# ğŸ¤– ä»é›¶å¼€å§‹å®ç° Transformer

æœ¬é¡¹ç›®æ˜¯ "Attention Is All You Need" (Vaswani et al., 2017) è®ºæ–‡ä¸­ Transformer æ¨¡å‹çš„ PyTorch å®Œæ•´å®ç°ã€‚

è¯¥å®ç°åŒ…å«ä¸€ä¸ªå®Œæ•´çš„ Encoder-Decoder æ¶æ„ï¼Œç”¨äº**è‹±ä¸­ï¼ˆEN-ZHï¼‰æœºå™¨ç¿»è¯‘**ä»»åŠ¡ã€‚é¡¹ç›®é‡ç‚¹åœ¨äºæ·±å…¥ç†è§£æ¨¡å‹çš„æ¯ä¸€ä¸ªæ„å»ºæ¨¡å—ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—å¯¹æ¯”å®éªŒæ¥åˆ†ææ¨¡å‹è¡Œä¸ºã€‚

## ç›®å½•

- [æ ¸å¿ƒç‰¹æ€§](https://www.google.com/search?q=%23-æ ¸å¿ƒç‰¹æ€§)
- [é¡¹ç›®ç»“æ„](https://www.google.com/search?q=%23-é¡¹ç›®ç»“æ„)
- [ç¯å¢ƒé…ç½®](https://www.google.com/search?q=%23-ç¯å¢ƒé…ç½®)
- [æ•°æ®é›†](https://www.google.com/search?q=%23-æ•°æ®é›†)
- [å¦‚ä½•è¿è¡Œ](https://www.google.com/search?q=%23-å¦‚ä½•è¿è¡Œ)
  - [è®­ç»ƒï¼ˆå¤ç°ä¸»è¦å®éªŒï¼‰](https://www.google.com/search?q=%231-è®­ç»ƒå¤ç°ä¸»è¦å®éªŒ)
  - [è¯„ä¼°ï¼ˆæµ‹è¯•é›†ï¼‰](https://www.google.com/search?q=%232-è¯„ä¼°æµ‹è¯•é›†)
- [ç¡¬ä»¶è¦æ±‚](https://www.google.com/search?q=%23-ç¡¬ä»¶è¦æ±‚)
- [å®éªŒç»“æœä¸åˆ†æ](https://www.google.com/search?q=%23-å®éªŒç»“æœä¸åˆ†æ)
  - [ä¸»è¦ç»“æœ](https://www.google.com/search?q=%231-ä¸»è¦ç»“æœ)
  - [å¯¹æ¯”å®éªŒ 1](https://www.google.com/search?q=%232-å¯¹æ¯”å®éªŒ-1è¿‡æ‹Ÿåˆ)
  - [å¯¹æ¯”å®éªŒ 2ï¼šæ¶ˆèå®éªŒï¼ˆç§»é™¤ä½ç½®ç¼–ç ï¼‰](https://www.google.com/search?q=%233-å¯¹æ¯”å®éªŒ-2æ¶ˆèå®éªŒç§»é™¤ä½ç½®ç¼–ç )
- [å‚è€ƒæ–‡çŒ®](https://www.google.com/search?q=%23-å‚è€ƒæ–‡çŒ®)

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

- **å®Œæ•´æ¶æ„**: å®ç°äº†å®Œæ•´çš„ Encoder-Decoder Transformer æ¶æ„ã€‚
- **æ ¸å¿ƒæ¨¡å—**: åŒ…å«ä»¥ä¸‹æ‰€æœ‰å…³é”®ç»„ä»¶çš„ä»é›¶å®ç°ï¼š
  - `ScaledDotProductAttention`
  - `MultiHeadAttention`
  - `PositionwiseFeedForward`
  - `PositionalEncoding` 
  - `EncoderLayer` å’Œ `DecoderLayer`
  - `Encoder` å’Œ `Decoder`
  - `TransformerSeq2Seq`
- **æ©ç æœºåˆ¶**:
  - **å¡«å……æ©ç  (Padding Mask)**ï¼šåœ¨ Encoder å’Œ Decoder ä¸­å¿½ç•¥ `<pad>` æ ‡è®°ã€‚
  - **å‰ç»æ©ç  (Look-ahead Mask)**ï¼šç”¨äº Decoderï¼Œç¡®ä¿åœ¨é¢„æµ‹æ—¶ä¸ä¼šâ€œå·çœ‹â€æœªæ¥çš„è¯ã€‚
- **è®­ç»ƒç­–ç•¥**:
  - å®ç°äº†æ ‡ç­¾å¹³æ»‘ï¼ˆLabel Smoothingï¼‰ã€‚
  - ç»“åˆ AdamW ä¼˜åŒ–å™¨å’Œæƒé‡è¡°å‡ï¼ˆWeight Decayï¼‰ã€‚
  - å®ç°äº†å¸¦ Warmup æ­¥æ•°çš„å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚
- **å¯å¤ç°æ€§**: æä¾›äº†ç²¾ç¡®çš„è®­ç»ƒå‘½ä»¤å’Œéšæœºç§å­ï¼Œä»¥ä¿è¯å®éªŒç»“æœçš„å¯å¤ç°æ€§ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ checkpoints/        # (è‡ªåŠ¨åˆ›å»º) å­˜æ”¾è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ (.pth) å’Œè¯è¡¨ (.json)
â”œâ”€â”€ data/               # (è‡ªåŠ¨åˆ›å»º) Hugging Face 'datasets' åº“çš„ç¼“å­˜ç›®å½•
â”œâ”€â”€ results/            # å­˜æ”¾è®­ç»ƒæ›²çº¿å›¾å’Œå®éªŒç»“æœ
â”‚   â”œâ”€â”€ successful_loss_curve.png  
â”‚   â”œâ”€â”€ overfitting_loss.png       
â”‚   â””â”€â”€ no_pe_loss.png             
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run.sh          # ç”¨äºå¯åŠ¨è®­ç»ƒçš„Shellè„šæœ¬
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py        # Transformer æ ¸å¿ƒæ¨¡å‹æ¶æ„
â”‚   â”œâ”€â”€ train.py        # è®­ç»ƒã€è¯„ä¼°ã€æ¨ç†çš„ä¸»è„šæœ¬
â”‚   â””â”€â”€ utils.py        # ç»˜å›¾ã€å‚æ•°ç»Ÿè®¡ç­‰è¾…åŠ©å‡½æ•°
â”œâ”€â”€ requirements.txt    # è¿è¡Œæ‰€éœ€çš„ Python ä¾èµ–
â””â”€â”€ README.md           # æœ¬æ–‡æ¡£
```

## âš™ï¸ ç¯å¢ƒé…ç½®

1. **å…‹éš†æœ¬ä»“åº“**

   ```
   git clone [https://github.com/huangmingye0819/transformer_demo](https://github.com/huangmingye0819/transformer_demo)
   cd transformer_demo
   ```

2. **åˆ›å»º Conda ç¯å¢ƒ (æ¨è)**

   ```
   conda create -n transformer python=3.10
   conda activate transformer
   ```

3. å®‰è£…ä¾èµ–

   æœ¬é¡¹ç›®ä¾èµ–äº PyTorch å’Œ Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­çš„ datasets, tokenizers, å’Œ torchmetricsã€‚

   ```
   # PyTorch
   # pip3 install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu118](https://download.pytorch.org/whl/cu118)
   
   # å®‰è£…å…¶ä»–ä¾èµ–
   pip install -r requirements.txt
   ```

   `requirements.txt` æ–‡ä»¶å†…å®¹åº”åŒ…å«ï¼š

   ```
   torch
   torchmetrics
   datasets
   tokenizers
   matplotlib
   tqdm
   ```

## ğŸ“š æ•°æ®é›†

æœ¬é¡¹ç›®ä½¿ç”¨ **IWSLT 2017 (en-zh)** æ•°æ®é›†ã€‚

ä½ **ä¸éœ€è¦**æ‰‹åŠ¨ä¸‹è½½ã€‚`src/train.py` è„šæœ¬ä¼šè‡ªåŠ¨ä½¿ç”¨ Hugging Face `datasets` åº“ä¸‹è½½å’ŒåŠ è½½æ•°æ®é›†ã€‚æ•°æ®å°†è¢«ç¼“å­˜åˆ°ä½ çš„ `~/.cache/huggingface/datasets` ç›®å½•æˆ–é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ `data/` æ–‡ä»¶å¤¹ä¸­ã€‚

- **è®­ç»ƒé›†**: çº¦ 230k å¥å¯¹
- **éªŒè¯é›†**: 879 å¥å¯¹

`src/data_loader.py` ä¸­çš„è„šæœ¬ä¼šè‡ªåŠ¨å¤„ç†ä»¥ä¸‹ä»»åŠ¡ï¼š

- è®­ç»ƒè‹±æ–‡å’Œä¸­æ–‡çš„ `WordLevel` BPE è¯è¡¨ã€‚
- å°†æ•°æ®é›† tokenåŒ– å¹¶ä¿å­˜åˆ°ç£ç›˜ï¼Œä»¥ä¾¿å¿«é€ŸåŠ è½½ã€‚
- åˆ›å»ºç”¨äºè®­ç»ƒçš„ `DataLoader`ã€‚

## ğŸš€ å¦‚ä½•è¿è¡Œ

æ‰€æœ‰æ“ä½œå‡é€šè¿‡ `src/train.py` è„šæœ¬æ‰§è¡Œã€‚

### 1. è®­ç»ƒï¼ˆå¤ç°ä¸»è¦å®éªŒï¼‰

è¿™æ˜¯ç”¨äºå¤ç°æŠ¥å‘Šä¸­æ¨¡å‹çš„ç²¾ç¡®å‘½ä»¤ã€‚è¯¥å‘½ä»¤ä½¿ç”¨äº†æœ€ä½³è¶…å‚æ•°é…ç½®ï¼ŒåŒ…æ‹¬æ‰€æœ‰æ­£åˆ™åŒ–æŠ€å·§ã€‚

```
python src/train.py \
    --embedding_dim 256 \
    --num_heads 8 \
    --feed_forward_dim 512 \
    --num_layers 4 \
    --batch_size 32 \
    --learning_rate 1e-4 \
    --num_epochs 30 \
    --dropout 0.3 \
    --label_smoothing 0.1 \
    --weight_decay 0.01 \
    --warmup_steps 4000 \
    --seed 42 \
    --save_path "checkpoints/iwslt_en_zh_12M.pth" \
    --plot_path "results/successful_loss_curve.png"
```

**å‚æ•°è¯´æ˜:**

- `--embedding_dim`: è¯ç»´åº¦
- `--num_heads`: æ³¨æ„åŠ›å¤´æ•°
- `--feed_forward_dim`: FFN å†…éƒ¨éšè—å±‚ç»´åº¦
- `--num_layers`: Encoder å’Œ Decoder å„è‡ªçš„å±‚æ•°
- `--batch_size`: æ‰¹é‡å¤§å°
- `--learning_rate`: æœ€å¤§å­¦ä¹ ç‡
- `--num_epochs`: è®­ç»ƒè½®æ•°
- `--dropout`: Dropout æ¯”ä¾‹
- `--label_smoothing`: æ ‡ç­¾å¹³æ»‘ç³»æ•°
- `--weight_decay`: AdamW ä¼˜åŒ–å™¨çš„æƒé‡è¡°å‡ç³»æ•°
- `--warmup_steps`: å­¦ä¹ ç‡é¢„çƒ­çš„æ­¥æ•°
- `--seed`: å›ºå®šéšæœºç§å­ï¼Œç”¨äºå¤ç°
- `--save_path`: æœ€ä½³æ¨¡å‹çš„ä¿å­˜è·¯å¾„
- `--plot_path`: è®­ç»ƒ/éªŒè¯æŸå¤±æ›²çº¿å›¾çš„ä¿å­˜è·¯å¾„


### 1. æ¨ç†ï¼ˆç¿»è¯‘æ–°å¥å­ï¼‰

åŠ è½½æ¨¡å‹å¹¶ç¿»è¯‘ä½ è¾“å…¥çš„å¥å­ï¼š

```
python translate.py 
```

è„šæœ¬å°†åŠ è½½æ¨¡å‹ï¼Œå¤„ç†è¾“å…¥ï¼Œå¹¶æ‰“å°å‡ºä¸­æ–‡ç¿»è¯‘ç»“æœã€‚ä½†æ˜¯è¦æ³¨æ„å‚æ•°è¦å’Œtrain.pyä¿æŒä¸€è‡´

## ğŸ’» ç¡¬ä»¶è¦æ±‚

- **GPU**: å¼ºçƒˆæ¨èä½¿ç”¨ NVIDIA GPUã€‚
- **æ˜¾å­˜ (VRAM)**:
  - å¯¹äºä¸Šè¿°çš„12Må‚æ•°é…ç½®ï¼ˆ`d_model=128`, `batch_size=32`ï¼‰ï¼Œè®­ç»ƒéœ€è¦çº¦ **6GB - 8GB** æ˜¾å­˜ã€‚
  - å¯¹äºæŠ¥å‘Šä¸­æåˆ°çš„28Må‚æ•°é…ç½®ï¼ˆ`d_model=256`ï¼‰ï¼Œæ˜¾å­˜éœ€æ±‚ä¼šæ˜¾è‘—å¢åŠ ï¼Œå»ºè®® **16GB** ä»¥ä¸Šã€‚
- **CPU/RAM**: æ•°æ®é¢„å¤„ç†åœ¨ CPU ä¸Šå®Œæˆï¼Œå»ºè®®è‡³å°‘ 16GB å†…å­˜ä»¥è·å¾—æµç•…ä½“éªŒã€‚

## ğŸ“Š å®éªŒç»“æœä¸åˆ†æ

### 1. ä¸»è¦ç»“æœï¼š

æˆ‘ä»¬æœ€ç»ˆé‡‡ç”¨äº† 28M å‚æ•°çš„è½»é‡çº§æ¨¡å‹ï¼Œå¹¶é…åˆäº†å¼ºæœ‰åŠ›çš„æ­£åˆ™åŒ–ç»„åˆï¼ˆDropout=0.3, æƒé‡è¡°å‡=0.01, æ ‡ç­¾å¹³æ»‘=0.1ï¼‰ã€‚

ä»ä¸‹æ–¹çš„æŸå¤±æ›²çº¿å¯ä»¥çœ‹å‡ºï¼Œè®­ç»ƒæŸå¤±ï¼ˆTraining Lossï¼‰å’ŒéªŒè¯æŸå¤±ï¼ˆValidation Lossï¼‰éƒ½åœ¨å¥åº·ä¸‹é™ï¼Œä¸”äºŒè€…ä¹‹é—´ä¿æŒç€è¾ƒå°çš„å·®è·ã€‚è¿™è¡¨æ˜æ¨¡å‹æœ‰æ•ˆå­¦ä¹ äº†ç¿»è¯‘ä»»åŠ¡ï¼ŒåŒæ—¶æˆåŠŸåœ°æŠ‘åˆ¶äº†è¿‡æ‹Ÿåˆã€‚

*(è¯·ç¡®ä¿å°†ä½ çš„**æˆåŠŸ**è®­ç»ƒæ›²çº¿å›¾å‘½åä¸º `successful_loss_curve.png` å¹¶æ”¾ç½®åœ¨ `results/` ç›®å½•ä¸‹)*

### 2. å¯¹Sæ¯”å®éªŒ 1ï¼šè¿‡æ‹Ÿåˆ

ä¸ºäº†å¯¹æ¯”ï¼Œæˆ‘ä»¬å°è¯•äº†å…¶ä»–å‚æ•°çš„æ¨¡å‹ã€‚

å¦‚ä¸‹å›¾ï¼ˆ`results/overfitting_loss.png`ï¼‰æ‰€ç¤ºï¼Œè¯¥æ¨¡å‹è¡¨ç°å‡º**ä¸¥é‡çš„è¿‡æ‹Ÿåˆ**ã€‚è®­ç»ƒæŸå¤±ï¼ˆè“çº¿ï¼‰è¿…é€Ÿä¸‹é™ï¼Œä½†éªŒè¯æŸå¤±ï¼ˆæ©™çº¿ï¼‰åœ¨ç¬¬ 5 ä¸ª Epoch åä¾¿åœæ­¢ä¸‹é™å¹¶å¼€å§‹åå¼¹ã€‚è¿™è¯æ˜äº†å¯¹äº IWSLT è¿™ç§è§„æ¨¡çš„æ•°æ®é›†ï¼Œæ¨¡å‹å®¹é‡è¿‡å¤§ä¸”ç¼ºä¹è¶³å¤Ÿæ­£åˆ™åŒ–ï¼Œä¼šå¯¼è‡´æ¨¡å‹â€œèƒŒè¯µâ€è®­ç»ƒæ•°æ®ï¼Œè€Œä¸§å¤±æ³›åŒ–èƒ½åŠ›ã€‚

*(è¯·å°†ä½ å¯¹åº”çš„è¿‡æ‹Ÿåˆå›¾å‘½åä¸º `overfitting_loss.png` æ”¾å…¥ `results/` æ–‡ä»¶å¤¹)*

### 3. å¯¹æ¯”å®éªŒ 2ï¼šæ¶ˆèå®éªŒï¼ˆç§»é™¤ä½ç½®ç¼–ç ï¼‰

ä¸ºäº†éªŒè¯ä½ç½®ç¼–ç çš„å¿…è¦æ€§ï¼Œæˆ‘ä»¬è¿›è¡Œäº†æ¶ˆèå®éªŒï¼š**å®Œå…¨ç§»é™¤äº†ä½ç½®ç¼–ç æ¨¡å—**ã€‚

ç»“æœå¦‚ä¸‹å›¾ï¼ˆ`results/no_pe_loss.png`ï¼‰æ‰€ç¤ºï¼Œæ¨¡å‹**å®Œå…¨æ— æ³•å­¦ä¹ **ã€‚è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŸå¤±å‡åœ¨é«˜ä½ï¼ˆçº¦ 2.8-3.4ï¼‰éšæœºæ³¢åŠ¨ï¼Œæ²¡æœ‰ä»»ä½•ä¸‹é™è¶‹åŠ¿ã€‚

è¿™æœ‰åŠ›åœ°è¯æ˜äº† Transformer æ¶æ„æœ¬èº«ä¸å…·å¤‡æ•æ‰åºåˆ—é¡ºåºçš„èƒ½åŠ›ï¼Œå®ƒå¿…é¡»ä¾èµ–å¤–éƒ¨æ³¨å…¥çš„ä½ç½®ä¿¡æ¯ï¼ˆå³ä½ç½®ç¼–ç ï¼‰æ‰èƒ½ç†è§£å¥å­çš„ç»“æ„å’Œè¯­æ³•ã€‚

*(è¯·å°†ä½ å¯¹åº”çš„â€œæ— æ³•å­¦ä¹ â€å›¾å‘½åä¸º `no_pe_loss.png` æ”¾å…¥ `results/` æ–‡ä»¶å¤¹)*

## ğŸ“„ å‚è€ƒæ–‡çŒ®

[1] Kyunghyun Cho, Bart Van MerriÃ«nboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares,
Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder
for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.
[2] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.
[3] Sepp Hochreiter and JÃ¼rgen Schmidhuber. Long short-term memory. Neural computation,
9(8):1735â€“1780, 1997.
[4] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. 2018.
[5] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,
Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified
text-to-text transformer. Journal of Machine Learning Research, 21(140):1â€“67, 2020.
[6] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning internal representations
by error propagation. Nature, 323(6088):533â€“536, 1986.
[7] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information
processing systems, 30, 2017.
